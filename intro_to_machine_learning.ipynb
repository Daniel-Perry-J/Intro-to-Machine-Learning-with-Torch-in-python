{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Daniel-Perry-J/Daniel-Perry-J/blob/main/intro_to_machine_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEW_iQ9cgS29"
      },
      "source": [
        "# What the *heck* even is machine learning ‚ùì‚ùó\n",
        "Well that's a really great, but big question! Machine learning can come in all different shapes and sizes, but some categories are:\n",
        "\n",
        "- <u>Supervised</u>: This is where you have some data paired up with \"labels\" or \"true\" values. This just means that you have data pairs of something like height matched up with a persons favourite colour. (Ex: {61 inches, blue})\n",
        "\n",
        " - <u>Regression</u>: This is where the thing that you are predicting is a series or singular scalar value. So based on the previous example our prompt to the model would be, given a person's favourite colour, what is their height.\n",
        "\n",
        " - <u>Classification</u>: This is where the thing that you are predicting is a series or singular categorical value. So based on the previous example our prompt to the model would be, given a person's height, what is their favourite colour.\n",
        "\n",
        "- <u>Unsupervised</u>: This is usually where algorithms like clustering come into play where you are trying to learn something about your data.\n",
        "\n",
        "- <u>Reinforcement</u>: You have probably seen those youtube videos where \"Teach AI How to Play MarioKart\", this is that! These algorithms are a little out of scope for this pseudo-lecture, but if you want to chat offline about this, these algorithms are actually the focus of a lot of my work!\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://www.researchgate.net/publication/354960266/figure/fig1/AS:1075175843983363@1633353305883/The-main-types-of-machine-learning-Main-approaches-include-classification-and.png\" width=700 height=auto/>\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iwq2WXdOmRFj"
      },
      "source": [
        "# Neural Networks üî•\n",
        "\n",
        "## Introduction üí°\n",
        "\n",
        "Neural networks have been the üåü*star child*üåü of machine learning as of late, and for good reason! Neural networks are what as known as \"universal function approximators\", this means that in the universe of any functions, a neural network can approximate the relation between input and output. This includes functions that you could never imagine, like the percent of cat a dog is! So neural networks will the focus of this pseudo lecture and tutorial. This is going to be more of an \"engineering\" styled approach to machine learning that will hopefully give you the tools to start making models from data today!\n",
        "\n",
        "\n",
        "## Basic Mathematics ü§îüí≠üìäüßÆüìù\n",
        "\n",
        "The basic mathematics of neural networks is actually really simple! Do you remember that very simple equation for a linear function: $y=mx+b$? Well great news! Neural networks are just that but like a bunch of times! If you have taken Math 204 here at Western then you are probably familiar with the idea matrices and matrix multiplication, this is the way that we write these linear equations for neural networks.\n",
        "\n",
        "One important note here though is that the composition of linear functions will result in another linear function: $m_2(m_1 x + b_1)+b_2 = m_3 x + b_3$. So to approximate any functions of any real complexity, we will need to introduce some nonlinear funcion that we will denote $\\phi$ smack dab in the middle of the function! Our new function looks like this: $m_2(\\phi(m_1 x + b_1))+b_2 \\neq m_3 x + b_3$, not so bad right, this is literally the fundemental of all neural networks.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://www.knime.com/sites/default/files/3-intro-deep-neural-networks.png\" width=500, height=auto/>\n",
        "</p>\n",
        "\n",
        "## Code ü§ñüíª\n",
        "\n",
        "Alright all of this is fine and dandy, but how the _heck_ do I write code for this stuff??\n",
        "Lucky for us there are a plethora of packages and frameworks in all different languages that make this stuff easy for us.\n",
        "For this we are going to stick with python and use the PyTorch library, there are a lot of other frameworks that are similar like TensorFlow and PyTorchLightning, but to keep things simple I am going to only use one library for demonstration as most of the things learned here are easily transferrable to other frameworks.\n",
        "\n",
        "## What are We Cookin'?? ü•ìüç≥ü•™\n",
        "\n",
        "For this tutorial we are going to be training a handwriting classifier, we will take in an image of someone's hand drawn number, and then our model will predict what the number that they wrote was!\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://production-media.paperswithcode.com/datasets/MNIST-0000000001-2e09631a_09liOmx.jpg\" width=500, height=auto/>\n",
        "</p>\n",
        "\n",
        "<p align=\"center\">\n",
        "  <b>Lets get to coding!</b>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhC6QIaTvDih",
        "outputId": "89a724b5-4ca0-4e73-954c-f7323716dd60"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST # Lucky for us someone already built this!\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.functional as f\n",
        "\n",
        "train_ds = MNIST(\n",
        "      root='/content/MNIST/',\n",
        "      train=True,\n",
        "      download=True,\n",
        "      transform=transforms.ToTensor()\n",
        "    )\n",
        "\n",
        "dev_ds = MNIST(\n",
        "      root='/content/MNIST/',\n",
        "      train=False,\n",
        "      download=True,\n",
        "      transform=transforms.ToTensor()\n",
        "    )\n",
        "\n",
        "# index of labels\n",
        "print(f\"{dev_ds[0][0].shape=}\")\n",
        "print(f\"{dev_ds[0][1]=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nio_-lLDx3YO"
      },
      "outputs": [],
      "source": [
        "activations = {\n",
        "    'ReLU': nn.ReLU(),\n",
        "    'ReLU6': nn.ReLU6(),\n",
        "    'LeakyReLU': nn.LeakyReLU(),\n",
        "    'Sigmoid': nn.Sigmoid(),\n",
        "    'Tanh': nn.Tanh(),\n",
        "    'ELU': nn.ELU(),\n",
        "    'PReLU': nn.PReLU(),\n",
        "    'SELU': nn.SELU()\n",
        "}\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, in_size, out_size, n_layers=3, hidden_size=128, act=\"ReLU\"):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.in_size = in_size\n",
        "        self.input_layer = nn.Linear(in_size, hidden_size)\n",
        "        self.hidden_layers = nn.ModuleList([nn.Linear(hidden_size, hidden_size) for _ in range(n_layers)])\n",
        "        self.output_layer = nn.Linear(hidden_size, out_size)\n",
        "        self.activation = activations[act]\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.reshape(-1, self.in_size)\n",
        "        x = self.input_layer(x)\n",
        "        x = self.activation(x)\n",
        "        for layer in self.hidden_layers:\n",
        "            x = layer(x)\n",
        "            x = self.activation(x)\n",
        "        x = self.output_layer(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCGR4qwB08VU",
        "outputId": "85f6f7a9-d5c1-4d3d-f298-b62053e7277d"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "epochs = 25 # number of iterations for learning\n",
        "lr = 0.001  # Correct learning rate used\n",
        "activation = \"ReLU\"\n",
        "hidden_size = 128\n",
        "n_layers = 3\n",
        "batch_size = 64\n",
        "\n",
        "model = NeuralNetwork(\n",
        "    in_size=784,              # This is 28*28 becuase are images are 28x28\n",
        "    out_size=10,              # This is 10, because we have 10 different classes (0-9)\n",
        "    n_layers=n_layers,\n",
        "    hidden_size=hidden_size,\n",
        "    act=activation,\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "dev_loader = DataLoader(dev_ds, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)  # Use lr variable\n",
        "\n",
        "for i in range(epochs):\n",
        "    running_loss = 0\n",
        "    for image, label in tqdm(train_loader, desc=\"Training\"):\n",
        "        optimizer.zero_grad()\n",
        "        prediction = model(image)\n",
        "        loss = criterion(prediction, label)\n",
        "        running_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f\"Train loss at epoch {i}: {running_loss / len(train_loader)}\")\n",
        "\n",
        "    running_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for image, label in tqdm(dev_loader, desc=\"Evaluating\"):\n",
        "            prediction = model(image)\n",
        "            loss = criterion(prediction, label)\n",
        "            running_loss += loss.item()\n",
        "    print(f\"Dev loss at epoch {i}: {running_loss / len(dev_loader)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGOfNmK7BTfW"
      },
      "source": [
        "# This is great but what now??\n",
        "\n",
        "Thats a great question, once you have a fully trained machine learning model, it's time to deploy!\n",
        "These models need the data to have \"matching shape\" which basically just means that if it was trained on images that were 28x28 pixels, then it can only generalize to those images.\n",
        "Another thing that these models cannot do is generalize to data types that are \"out of distribution\", which basically just means that if we train it on images of numbers, it wont generalize to smiley faces or letters (but I emplore you to try in the next section).\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://files.oaiusercontent.com/file-OlScYgSdL0bgKvRKUnXKOGqF?se=2023-12-02T00%3A17%3A16Z&sp=r&sv=2021-08-06&sr=b&rscc=max-age%3D31536000%2C%20immutable&rscd=attachment%3B%20filename%3D99a3fb82-b725-4e41-ba21-4a3e7c938093.webp&sig=OdCIDd04xyXzuYJupD0dYm3tFoUnAIOt0zQMYvzKo9Q%3D\" width=300, height=auto/>\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 825,
          "referenced_widgets": [
            "075365d1296b42c9ada6fd65431133cc",
            "6b4ab1b53be74053a062831da18e20e9",
            "ff14c8274d8242ceae8b6614b51a938e",
            "0ca79466aec0487aa75b1ef00d7e2340",
            "33405151387047f3aa3cfcf2a3710aff",
            "ca07d80394a444208239ea2edfd5785f",
            "42357fc91ed24a9fa07bde8cd46650e2",
            "71cc4d4640a0448f942aad2db590a6b5",
            "703bb9c748214f658af2c49c273e4946",
            "a74174583d3041998a02b288d6ce9348",
            "a6c92b13c0704271ada714904feb64c6"
          ]
        },
        "id": "z2gyVYl3BpP9",
        "outputId": "4467387b-4b5e-42fa-9c59-4a6346589425"
      },
      "outputs": [],
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageOps\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "import io\n",
        "\n",
        "canvas_html = \"\"\"\n",
        "<canvas width=\"280px\" height=\"280px\" style=\"border:1px solid black;\"></canvas>\n",
        "<button id=\"save_button\">Save</button>\n",
        "<button id=\"clear_button\">Clear</button>\n",
        "<script>\n",
        "var canvas = document.querySelector('canvas');\n",
        "var ctx = canvas.getContext('2d');\n",
        "var save_button = document.getElementById('save_button');\n",
        "var clear_button = document.getElementById('clear_button');\n",
        "\n",
        "var mouse = {x: 0, y: 0}\n",
        "var last_mouse = {x: 0, y: 0}\n",
        "\n",
        "/* Mouse Capturing Work */\n",
        "canvas.addEventListener('mousemove', function(e) {\n",
        "    last_mouse.x = mouse.x;\n",
        "    last_mouse.y = mouse.y;\n",
        "\n",
        "    mouse.x = e.pageX - this.offsetLeft;\n",
        "    mouse.y = e.pageY - this.offsetTop;\n",
        "}, false);\n",
        "\n",
        "/* Drawing on Paint App */\n",
        "ctx.lineWidth = 10;\n",
        "ctx.lineJoin = 'round';\n",
        "ctx.lineCap = 'round';\n",
        "ctx.strokeStyle = 'black';\n",
        "\n",
        "canvas.addEventListener('mousedown', function(e) {\n",
        "    canvas.addEventListener('mousemove', onPaint, false);\n",
        "}, false);\n",
        "\n",
        "canvas.addEventListener('mouseup', function() {\n",
        "    canvas.removeEventListener('mousemove', onPaint, false);\n",
        "}, false);\n",
        "\n",
        "var onPaint = function() {\n",
        "    ctx.beginPath();\n",
        "    ctx.moveTo(last_mouse.x, last_mouse.y);\n",
        "    ctx.lineTo(mouse.x, mouse.y);\n",
        "    ctx.closePath();\n",
        "    ctx.stroke();\n",
        "};\n",
        "\n",
        "save_button.addEventListener('click', function() {\n",
        "    var image_data = canvas.toDataURL('image/png').replace(\"image/png\", \"image/octet-stream\");\n",
        "    var link = document.createElement('a');\n",
        "    link.download = 'drawing.jpg';\n",
        "    link.href = image_data;\n",
        "    link.click();\n",
        "});\n",
        "\n",
        "clear_button.addEventListener('click', function() {\n",
        "    ctx.clearRect(0, 0, canvas.width, canvas.height);\n",
        "});\n",
        "\n",
        "</script>\n",
        "\"\"\"\n",
        "drawing_pad = widgets.HTML(value=canvas_html)\n",
        "display(drawing_pad)\n",
        "\n",
        "button = widgets.Button(description=\"Predict\")\n",
        "output = widgets.Output()\n",
        "\n",
        "# Create a file upload widget\n",
        "uploader = widgets.FileUpload(\n",
        "    accept='.jpg',  # Accept only .png files\n",
        "    multiple=False  # Allow only single file upload\n",
        ")\n",
        "predict_button = widgets.Button(description=\"Predict\")\n",
        "\n",
        "def on_predict_button_clicked(b):\n",
        "    if uploader.value:\n",
        "        uploaded_file = next(iter(uploader.value.values()))\n",
        "        image_data = io.BytesIO(uploaded_file['content'])\n",
        "        image = Image.open(image_data)\n",
        "\n",
        "        image_resized = transforms.Resize((28, 28))(image)\n",
        "        image_tensor = transforms.ToTensor()(image_resized)[-1]\n",
        "\n",
        "\n",
        "        # Make a prediction\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            prediction = model(image_tensor.unsqueeze(0))\n",
        "            predicted_label = prediction.argmax(dim=1, keepdim=True)\n",
        "\n",
        "        # Display the prediction\n",
        "        with output:\n",
        "            clear_output(wait=True)\n",
        "            plt.clf()\n",
        "            plt.imshow(image_tensor, cmap='gray')\n",
        "            plt.title(\"What the model sees\")\n",
        "            plt.xticks([])\n",
        "            plt.yticks([])\n",
        "            plt.xlabel(f'Models Prediction: {predicted_label.item()}')\n",
        "            plt.show()\n",
        "            print(\"Predicted Digit:\", predicted_label.item())\n",
        "\n",
        "predict_button.on_click(on_predict_button_clicked)\n",
        "display(uploader, predict_button, output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZeXp_fsruib"
      },
      "source": [
        "# This is great, but I want to learn to approximate more functions\n",
        "\n",
        "That's so great to hear! You have just some of the fundementals of machine learning.\n",
        "The main thing that we would need to change is the `dataset_class`, which is just the thing that we stole from some one else at the begining.\n",
        "I stole this from someone else so as to not overload people with arbitrary information that they may not have needed / wanted.\n",
        "These dataset classes are basically just big \"array-likes\", which just means that I can index into them like a list!\n",
        "So if I want to get the first item out of a dataset, I can do something like `input, label = ds[0]`.\n",
        "\n",
        "## The Main Functions\n",
        "\n",
        "- `__init__(self, **kwargs)`: This is the class function that sets everything up for us.\n",
        "This could contain a lot of different things but it generally entails loading our custom data into memory, and saving some of our preferences for viewing this data.\n",
        "\n",
        "- `__getitem__(self, index)`: This is just the function that our dataloader calls behind the scenes. So we just need to set up a way to grab each unique element of our custom data.\n",
        "If our data is tabular, then we our first element will be the first row, and the last element will be the last row of the table.\n",
        "\n",
        "- `__len__(self,)`: This function just tells us how many items are in our dataset, which allows us to do `len(ds)`. This is important because if we don't know how many elements are in our arraylike how do we know when to stop trying to get new datapoints?\n",
        "\n",
        "___\n",
        "\n",
        "Cool! Let's write a basic dataset that is tabular!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPYnAjLvrtK5",
        "outputId": "27975547-665d-4171-bdc0-83894ff11411"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "class CaliforniaHousingDataSet(torch.utils.data.Dataset):\n",
        "    def __init__(self, split: str, means=None, stds=None):\n",
        "        self.data = pd.read_csv(f\"/content/sample_data/california_housing_{split}.csv\")\n",
        "\n",
        "        if means is None and stds is None:\n",
        "            self.means = self.data.mean()\n",
        "            self.stds = self.data.std()\n",
        "        else:\n",
        "            self.means = means\n",
        "            self.stds = stds\n",
        "\n",
        "        self.data = (self.data - self.means) / self.stds\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        x = torch.stack(\n",
        "            [\n",
        "                torch.tensor(row[\"housing_median_age\"], dtype=torch.float32),\n",
        "                torch.tensor(row[\"total_rooms\"], dtype=torch.float32),\n",
        "                torch.tensor(row[\"total_bedrooms\"], dtype=torch.float32),\n",
        "                torch.tensor(row[\"population\"], dtype=torch.float32),\n",
        "                torch.tensor(row[\"households\"], dtype=torch.float32),\n",
        "                torch.tensor(row[\"median_income\"], dtype=torch.float32),\n",
        "            ]\n",
        "        )\n",
        "        y = torch.tensor([row[\"median_house_value\"]], dtype=torch.float32)\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self,):\n",
        "        return len(self.data)\n",
        "\n",
        "    def get_stats(self,):\n",
        "        return {\"means\": self.means, \"stds\": self.stds}\n",
        "\n",
        "train_ds = CaliforniaHousingDataSet(split=\"train\")\n",
        "dev_ds = CaliforniaHousingDataSet(split=\"test\", **train_ds.get_stats())\n",
        "print(dev_ds[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynW0j5t74us7",
        "outputId": "3bf12f2d-a9ba-400e-b8ec-256d15e6b955"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "epochs = 25 # how many iterations of learning\n",
        "lr = 0.001  # Correct learning rate used\n",
        "activation = \"ReLU\"\n",
        "hidden_size = 128\n",
        "n_layers = 3\n",
        "batch_size = 64\n",
        "\n",
        "model = NeuralNetwork(\n",
        "    in_size=6,               # This is 6 because there are 6 input features\n",
        "    out_size=1,              # we have one feature that we are predicting\n",
        "    n_layers=n_layers,\n",
        "    hidden_size=hidden_size,\n",
        "    act=activation,\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "dev_loader = DataLoader(dev_ds, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)  # Use lr variable\n",
        "for i in range(epochs):\n",
        "    running_loss = 0\n",
        "    for features, label in tqdm(train_loader, desc=\"Training\"):\n",
        "        optimizer.zero_grad()\n",
        "        prediction = model(features)\n",
        "        loss = criterion(prediction, label)\n",
        "        running_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f\"Train loss at epoch {i}: {running_loss / len(train_loader)}\")\n",
        "\n",
        "    running_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for features, label in tqdm(dev_loader, desc=\"Evaluating\"):\n",
        "            prediction = model(features)\n",
        "            loss = criterion(prediction, label)\n",
        "            running_loss += loss.item()\n",
        "    print(f\"Dev loss at epoch {i}: {running_loss / len(dev_loader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I45_QY4Ku8AF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "075365d1296b42c9ada6fd65431133cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b4ab1b53be74053a062831da18e20e9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ff14c8274d8242ceae8b6614b51a938e",
            "value": "\n<canvas width=\"280px\" height=\"280px\" style=\"border:1px solid black;\"></canvas>\n<button id=\"save_button\">Save</button>\n<button id=\"clear_button\">Clear</button>\n<script>\nvar canvas = document.querySelector('canvas');\nvar ctx = canvas.getContext('2d');\nvar save_button = document.getElementById('save_button');\nvar clear_button = document.getElementById('clear_button');\n\nvar mouse = {x: 0, y: 0}\nvar last_mouse = {x: 0, y: 0}\n\n/* Mouse Capturing Work */\ncanvas.addEventListener('mousemove', function(e) {\n    last_mouse.x = mouse.x;\n    last_mouse.y = mouse.y;\n\n    mouse.x = e.pageX - this.offsetLeft;\n    mouse.y = e.pageY - this.offsetTop;\n}, false);\n\n/* Drawing on Paint App */\nctx.lineWidth = 10;\nctx.lineJoin = 'round';\nctx.lineCap = 'round';\nctx.strokeStyle = 'black';\n\ncanvas.addEventListener('mousedown', function(e) {\n    canvas.addEventListener('mousemove', onPaint, false);\n}, false);\n\ncanvas.addEventListener('mouseup', function() {\n    canvas.removeEventListener('mousemove', onPaint, false);\n}, false);\n\nvar onPaint = function() {\n    ctx.beginPath();\n    ctx.moveTo(last_mouse.x, last_mouse.y);\n    ctx.lineTo(mouse.x, mouse.y);\n    ctx.closePath();\n    ctx.stroke();\n};\n\nsave_button.addEventListener('click', function() {\n    var image_data = canvas.toDataURL('image/png').replace(\"image/png\", \"image/octet-stream\");\n    var link = document.createElement('a');\n    link.download = 'drawing.jpg';\n    link.href = image_data;\n    link.click();\n});\n\nclear_button.addEventListener('click', function() {\n    ctx.clearRect(0, 0, canvas.width, canvas.height);\n});\n\n</script>\n"
          }
        },
        "0ca79466aec0487aa75b1ef00d7e2340": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FileUploadModel",
          "state": {
            "_counter": 4,
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FileUploadModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "FileUploadView",
            "accept": ".jpg",
            "button_style": "",
            "data": [
              null
            ],
            "description": "Upload",
            "description_tooltip": null,
            "disabled": false,
            "error": "",
            "icon": "upload",
            "layout": "IPY_MODEL_33405151387047f3aa3cfcf2a3710aff",
            "metadata": [
              {
                "lastModified": 1701497910001,
                "name": "drawing (3).jpg",
                "size": 6798,
                "type": "image/jpeg"
              }
            ],
            "multiple": false,
            "style": "IPY_MODEL_ca07d80394a444208239ea2edfd5785f"
          }
        },
        "33405151387047f3aa3cfcf2a3710aff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42357fc91ed24a9fa07bde8cd46650e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Predict",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_71cc4d4640a0448f942aad2db590a6b5",
            "style": "IPY_MODEL_703bb9c748214f658af2c49c273e4946",
            "tooltip": ""
          }
        },
        "6b4ab1b53be74053a062831da18e20e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "703bb9c748214f658af2c49c273e4946": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "71cc4d4640a0448f942aad2db590a6b5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6c92b13c0704271ada714904feb64c6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a74174583d3041998a02b288d6ce9348": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_a6c92b13c0704271ada714904feb64c6",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "image/png": "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\n",
                  "text/plain": "<Figure size 640x480 with 1 Axes>"
                },
                "metadata": {},
                "output_type": "display_data"
              },
              {
                "name": "stdout",
                "output_type": "stream",
                "text": [
                  "Predicted Digit: 8\n"
                ]
              }
            ]
          }
        },
        "ca07d80394a444208239ea2edfd5785f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "ff14c8274d8242ceae8b6614b51a938e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
